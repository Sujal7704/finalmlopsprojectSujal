dataset: data/raw.csv

preprocessing:
  scale: true
  scaler: StandardScaler   # options: StandardScaler, MinMaxScaler
  smote: true
  pca: true
  pca_components: 0.95
  poly_features: true
  poly_degree: 2
  merge_classes: true

models:
  LogisticRegression:
    C: [0.01, 0.1, 1.0, 10.0]
    max_iter: [200, 500, 1000]
    random_state: [42]

  RandomForestClassifier:
    n_estimators: [100, 200, 300, 500]
    max_depth: [5, 7, 10, null]
    min_samples_split: [2, 5, 10]
    random_state: [42]

  XGBClassifier:
    n_estimators: [100, 200, 300]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    max_depth: [3, 5, 7, 10]
    subsample: [0.7, 0.8, 1.0]
    colsample_bytree: [0.7, 0.8, 1.0]
    random_state: [42]

  GradientBoostingClassifier:
    n_estimators: [100, 200, 300]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [3, 5, 7]
    random_state: [42]

  MLPClassifier:
    hidden_layer_sizes: [[100], [100, 50], [200, 100, 50]]
    activation: ["relu", "tanh"]
    solver: ["adam", "sgd"]
    learning_rate_init: [0.001, 0.01]
    max_iter: [300, 500, 1000]
    random_state: [42]

  LGBMClassifier:
    n_estimators: [100, 200, 300]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [-1, 5, 7, 10]
    random_state: [42]

  CatBoostClassifier:
    iterations: [200, 300, 500]
    depth: [4, 6, 8]
    learning_rate: [0.01, 0.05, 0.1]
    random_state: [42]

  VotingClassifier:
    voting: ["soft", "hard"]
    estimators:
      rf:
        n_estimators: [200, 300]
        max_depth: [5, 7]
        random_state: [42]
      xgb:
        n_estimators: [200, 300]
        learning_rate: [0.05, 0.1]
        max_depth: [5, 7]
        random_state: [42]
      svc:
        C: [0.1, 1.0, 10.0]
        kernel: ["linear", "rbf"]
        probability: [True]
        random_state: [42]

training:
  test_size: 0.2
  random_state: 42